{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cuda.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOVBYz7qTppDjMGTOsLm7bn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimdongyeob/gitpractice/blob/master/cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iubqCQfjsVur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "bda4b83a-ff94-4096-dd92-c26aa2a8e2e1"
      },
      "source": [
        "#cuda exercises\n",
        "#I don't have nvidia gpu....ㅜㅜㅜ\n",
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE93AxHpslag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "185583a4-069f-491e-b863-51065f09504f"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-j4cg39b0\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-j4cg39b0\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=1501c615c89aad17ae277aeeb78858a0171835e192a3b51cc61ff2bda5f6a924\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_p2s_lwt/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7Xvx4zztWOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fb553933-07a1-4cbc-989c-6cbd11e360b3"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k11O7pK6eqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b2a8588d-1c65-4573-f937-88e406104c58"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "*c = *a + *b;\n",
        "}\n",
        "__global__ void hellocuda(void){\n",
        "    printf(\"Hello, and fuck you\\n\");\n",
        "}\n",
        "int main() {\n",
        "int a, b, c;\n",
        "// host copies of variables a, b & c\n",
        "int *d_a, *d_b, *d_c;\n",
        "// device copies of variables a, b & c\n",
        "int size = sizeof(int);\n",
        "// Allocate space for device copies of a, b, c\n",
        "cudaMalloc((void **)&d_a, size);\n",
        "cudaMalloc((void **)&d_b, size);\n",
        "cudaMalloc((void **)&d_c, size);\n",
        "// Setup input values  \n",
        "c = 0;\n",
        "a = 3;\n",
        "b = 5;\n",
        "// Copy inputs to device\n",
        "cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "// Launch add() kernel on GPU\n",
        "add<<<1,1>>>(d_a, d_b, d_c);\n",
        "\n",
        "// Copy result back to host\n",
        "cudaError err = cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "  if(err!=cudaSuccess) {\n",
        "      printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "printf(\"result is %d\\n\",c);\n",
        "// Cleanup\n",
        "cudaFree(d_a);\n",
        "cudaFree(d_b);\n",
        "cudaFree(d_c);\n",
        "return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result is 8\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFx2nrsL7XS9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "db977cc2-0dcb-4946-9827-f41d9617e0f7"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__ void square(float *d_out, float *d_in) {\n",
        "\t\tint idx = threadIdx.x;\n",
        "\t\tfloat f = d_in[idx];\n",
        "\t\td_out[idx]=f*f;\n",
        "\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv){\n",
        "\t\tconst int array_size=60;\n",
        "\t\tconst int array_bytes = array_size*sizeof(float);\n",
        "\n",
        "\t\tfloat h_in[array_size];\n",
        "\t\tfor (int i = 0; i<array_size; i++){\n",
        "\t\t\t\th_in[i] = float(i);\n",
        "\t\t}\n",
        "\t\tfloat h_out[array_size];\n",
        "\n",
        "\t\tfloat *d_in;\n",
        "\t\tfloat *d_out;\n",
        "\n",
        "\t\tcudaMalloc((void**) &d_in, array_bytes);\n",
        "\t\tcudaMalloc((void**) &d_out, array_bytes);\n",
        "\n",
        "\t\tcudaMemcpy(d_in, h_in, array_bytes, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\n",
        "\t\tsquare<<<1,array_size>>>(d_out, d_in);\n",
        "\t\tcudaMemcpy(h_out, d_out, array_bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\t\tfor (int i=0; i<array_size; i++){\n",
        "\t\t\t\tprintf(\"%f\", h_out[i]);\n",
        "\t\t\t\tprintf(((i%4)!=3)? \"\\t\":\"\\n\");\n",
        "\t\t}\n",
        "\n",
        "\t\tprintf(\"\\n\");\n",
        "\n",
        "\t\tfor (int i=0; i<array_size; i++){\n",
        "\t\t\t\tprintf(\"%f\", h_in[i]);\n",
        "\t\t\t\tprintf(((i%4)!=3)? \"\\t\":\"\\n\");\n",
        "\t\t}\n",
        "\t\tcudaFree(d_in);\n",
        "\t\tcudaFree(d_out);\n",
        "\t\treturn 0;\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.000000\t1.000000\t4.000000\t9.000000\n",
            "16.000000\t25.000000\t36.000000\t49.000000\n",
            "64.000000\t81.000000\t100.000000\t121.000000\n",
            "144.000000\t169.000000\t196.000000\t225.000000\n",
            "256.000000\t289.000000\t324.000000\t361.000000\n",
            "400.000000\t441.000000\t484.000000\t529.000000\n",
            "576.000000\t625.000000\t676.000000\t729.000000\n",
            "784.000000\t841.000000\t900.000000\t961.000000\n",
            "1024.000000\t1089.000000\t1156.000000\t1225.000000\n",
            "1296.000000\t1369.000000\t1444.000000\t1521.000000\n",
            "1600.000000\t1681.000000\t1764.000000\t1849.000000\n",
            "1936.000000\t2025.000000\t2116.000000\t2209.000000\n",
            "2304.000000\t2401.000000\t2500.000000\t2601.000000\n",
            "2704.000000\t2809.000000\t2916.000000\t3025.000000\n",
            "3136.000000\t3249.000000\t3364.000000\t3481.000000\n",
            "\n",
            "0.000000\t1.000000\t2.000000\t3.000000\n",
            "4.000000\t5.000000\t6.000000\t7.000000\n",
            "8.000000\t9.000000\t10.000000\t11.000000\n",
            "12.000000\t13.000000\t14.000000\t15.000000\n",
            "16.000000\t17.000000\t18.000000\t19.000000\n",
            "20.000000\t21.000000\t22.000000\t23.000000\n",
            "24.000000\t25.000000\t26.000000\t27.000000\n",
            "28.000000\t29.000000\t30.000000\t31.000000\n",
            "32.000000\t33.000000\t34.000000\t35.000000\n",
            "36.000000\t37.000000\t38.000000\t39.000000\n",
            "40.000000\t41.000000\t42.000000\t43.000000\n",
            "44.000000\t45.000000\t46.000000\t47.000000\n",
            "48.000000\t49.000000\t50.000000\t51.000000\n",
            "52.000000\t53.000000\t54.000000\t55.000000\n",
            "56.000000\t57.000000\t58.000000\t59.000000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfoNuyz891ny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7e806d0d-ee43-4973-980c-478fcda6fd21"
      },
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include <stdio.h>\n",
        "__global__ void helloCUDA(void){\n",
        "    printf(\"Hello CuDA from GPU!\\n\");\n",
        "}\n",
        "int main(void){\n",
        "    printf(\"Hello GPU\\n\");\n",
        "    helloCUDA <<<1,10>>>();\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello GPU\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bD3bvIya-Au",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "ccc6c2b0-a931-48a6-9027-37fd53880348"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#define NUM_BLOCKS 16\n",
        "#define BLOCK_WIDTH 1\n",
        "__global__ void hello(){\n",
        "    printf(\"hello world! I'm a thread %d, block %d\\n\", threadIdx.x, blockIdx.x);\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv){\n",
        "    hello<<<2,10>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    printf(\"That's all!\\n\");\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello world! I'm a thread 0, block 0\n",
            "hello world! I'm a thread 1, block 0\n",
            "hello world! I'm a thread 2, block 0\n",
            "hello world! I'm a thread 3, block 0\n",
            "hello world! I'm a thread 4, block 0\n",
            "hello world! I'm a thread 5, block 0\n",
            "hello world! I'm a thread 6, block 0\n",
            "hello world! I'm a thread 7, block 0\n",
            "hello world! I'm a thread 8, block 0\n",
            "hello world! I'm a thread 9, block 0\n",
            "hello world! I'm a thread 0, block 1\n",
            "hello world! I'm a thread 1, block 1\n",
            "hello world! I'm a thread 2, block 1\n",
            "hello world! I'm a thread 3, block 1\n",
            "hello world! I'm a thread 4, block 1\n",
            "hello world! I'm a thread 5, block 1\n",
            "hello world! I'm a thread 6, block 1\n",
            "hello world! I'm a thread 7, block 1\n",
            "hello world! I'm a thread 8, block 1\n",
            "hello world! I'm a thread 9, block 1\n",
            "That's all!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNf_bkRlSyhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}